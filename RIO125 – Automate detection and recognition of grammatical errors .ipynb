{"cells":[{"cell_type":"code","execution_count":11,"id":"127a621c","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"127a621c","executionInfo":{"status":"ok","timestamp":1713072248379,"user_tz":-330,"elapsed":5231,"user":{"displayName":"Lightning Thunder","userId":"16749741163451614519"}},"outputId":"98bfe394-33b3-403b-f6a5-ab5a8e4f2650"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}],"source":["import pandas as pd\n","import re\n","import string\n","from sklearn.model_selection import train_test_split\n","from nltk.tokenize import word_tokenize\n","from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizer\n","import nltk\n","nltk.download('wordnet')\n","nltk.download('stopwords')\n","import nltk\n","nltk.download('punkt')\n","\n","\n","# Load the dataset\n","df = pd.read_csv(\"/content/sample_data/input_data.csv\")  # Replace \"your_dataset.csv\" with the path to your dataset\n","\n","# Data Preprocessing\n","def preprocess_text(text):\n","    # Lowercase the text\n","    text = text.lower()\n","\n","    # Remove punctuation\n","    text = text.translate(str.maketrans('', '', string.punctuation))\n","\n","    # Tokenization\n","    tokens = word_tokenize(text)\n","\n","    # Remove stopwords\n","    stop_words = set(stopwords.words('english'))\n","    tokens = [word for word in tokens if word not in stop_words]\n","\n","    # Lemmatization\n","    lemmatizer = WordNetLemmatizer()\n","    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n","\n","    # Join tokens back into a string\n","    preprocessed_text = ' '.join(tokens)\n","\n","    return preprocessed_text\n","\n","# Apply preprocessing to the text column\n","df['processed_text'] = df['text'].apply(preprocess_text)\n","\n","# Split the dataset into training, validation, and testing sets\n","train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n","val_df, test_df = train_test_split(test_df, test_size=0.5, random_state=42)\n","\n","# Save preprocessed datasets\n","train_df.to_csv(\"train_dataset.csv\", index=False)\n","val_df.to_csv(\"val_dataset.csv\", index=False)\n","test_df.to_csv(\"test_dataset.csv\", index=False)\n"]},{"cell_type":"code","execution_count":12,"id":"d4fd26b6","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d4fd26b6","executionInfo":{"status":"ok","timestamp":1713072263213,"user_tz":-330,"elapsed":10130,"user":{"displayName":"Lightning Thunder","userId":"16749741163451614519"}},"outputId":"028dc5ed-9340-4049-8c06-fdc8fd44acc4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Head of Train Dataset:\n","                                                text  label  \\\n","0  My friends and I will have a beer party to che...      1   \n","1  Sometimes I woke up in the middle of the night...      1   \n","2  My friend introduce the wab lang-8 which can i...      0   \n","3  We talked many things through the night yester...      0   \n","4  Especially European must mind why I speak the ...      0   \n","\n","                                      processed_text  \n","0        friend beer party cheer korea football team  \n","1                sometimes woke middle night itching  \n","2         friend introduce wab lang8 improve english  \n","3  talked many thing night yesterday head hurt wa...  \n","4  especially european must mind speak letter r e...  \n","\n","Head of Validation Dataset:\n","                                                text  label  \\\n","0        He said that he went for a swim in the sea.      1   \n","1           I would like to listen to operas loudly.      1   \n","2  Today, a Korean scientist has successfully mad...      1   \n","3  Because it continued the thought which I would...      1   \n","4  If you have been said to be\" powerful\" since y...      1   \n","\n","                                      processed_text  \n","0                                 said went swim sea  \n","1                     would like listen opera loudly  \n","2  today korean scientist successfully made soft ...  \n","3          continued thought would write diary later  \n","4                      said powerful since childhood  \n","\n","Head of Test Dataset:\n","                                                text  label  \\\n","0                And It is a good experience for me.      0   \n","1  After the vacation, I was very busy because I ...      1   \n","2                   I'm back from swimming pool now.      0   \n","3    I am a big fan of the Toronto Blue Jays of MLB.      1   \n","4  It’s a finish after sprinkling grilled meat sa...      0   \n","\n","                           processed_text  \n","0                         good experience  \n","1               vacation busy report work  \n","2                   im back swimming pool  \n","3            big fan toronto blue jay mlb  \n","4  ’ finish sprinkling grilled meat sauce  \n"]}],"source":["import pandas as pd\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","# Load preprocessed datasets\n","train_df = pd.read_csv(\"train_dataset.csv\")\n","val_df = pd.read_csv(\"val_dataset.csv\")\n","test_df = pd.read_csv(\"test_dataset.csv\")\n","\n","# Handle missing values\n","train_df.dropna(subset=['processed_text'], inplace=True)\n","val_df.dropna(subset=['processed_text'], inplace=True)\n","test_df.dropna(subset=['processed_text'], inplace=True)\n","\n","# Print the head of updated datasets\n","print(\"Head of Train Dataset:\")\n","print(train_df.head())\n","\n","print(\"\\nHead of Validation Dataset:\")\n","print(val_df.head())\n","\n","print(\"\\nHead of Test Dataset:\")\n","print(test_df.head())\n","\n","# Feature Engineering\n","def extract_features(df):\n","    # TF-IDF Vectorization\n","    tfidf_vectorizer = TfidfVectorizer(max_features=1000)  # Adjust max_features as needed\n","    tfidf_features = tfidf_vectorizer.fit_transform(df['processed_text']).toarray()\n","\n","    return tfidf_features\n","\n","# Extract features for training, validation, and testing sets\n","train_features = extract_features(train_df)\n","val_features = extract_features(val_df)\n","test_features = extract_features(test_df)\n","\n","# Save extracted features\n","pd.DataFrame(train_features).to_csv(\"train_features.csv\", index=False, header=False)\n","pd.DataFrame(val_features).to_csv(\"val_features.csv\", index=False, header=False)\n","pd.DataFrame(test_features).to_csv(\"test_features.csv\", index=False, header=False)\n"]},{"cell_type":"code","execution_count":13,"id":"2fda15bc","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2fda15bc","executionInfo":{"status":"ok","timestamp":1713072271522,"user_tz":-330,"elapsed":4627,"user":{"displayName":"Lightning Thunder","userId":"16749741163451614519"}},"outputId":"9e65e4a9-94eb-42ed-f8e8-04b8a5b82789"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train Tokenized Shape: torch.Size([15988, 26])\n","Validation Tokenized Shape: torch.Size([1998, 18])\n","Test Tokenized Shape: torch.Size([2000, 20])\n"]}],"source":["import pandas as pd\n","from transformers import BertTokenizer\n","\n","# Load preprocessed dataset\n","train_df = pd.read_csv(\"train_dataset.csv\")\n","val_df = pd.read_csv(\"val_dataset.csv\")\n","test_df = pd.read_csv(\"test_dataset.csv\")\n","\n","# Initialize BERT tokenizer\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","\n","def tokenize_text(df):\n","    # Drop rows with missing or empty 'processed_text'\n","    df = df.dropna(subset=['processed_text'])\n","    df = df[df['processed_text'] != '']\n","\n","    # Tokenize the text data\n","    tokenized_data = tokenizer(df['processed_text'].tolist(), padding=True, truncation=True, return_tensors='pt')\n","\n","    return tokenized_data\n","\n","train_tokenized = tokenize_text(train_df)\n","val_tokenized = tokenize_text(val_df)\n","test_tokenized = tokenize_text(test_df)\n","\n","# Print tokenized data shapes\n","print(\"Train Tokenized Shape:\", train_tokenized['input_ids'].shape)\n","print(\"Validation Tokenized Shape:\", val_tokenized['input_ids'].shape)\n","print(\"Test Tokenized Shape:\", test_tokenized['input_ids'].shape)\n"]},{"cell_type":"code","execution_count":14,"id":"260bb584","metadata":{"id":"260bb584","executionInfo":{"status":"ok","timestamp":1713072275507,"user_tz":-330,"elapsed":517,"user":{"displayName":"Lightning Thunder","userId":"16749741163451614519"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from transformers import BertModel\n","\n","class BertClassifier(nn.Module):\n","    def __init__(self, num_classes):\n","        super(BertClassifier, self).__init__()\n","        self.bert = BertModel.from_pretrained('bert-base-uncased')\n","        self.dropout = nn.Dropout(0.1)  # Adjust dropout probability as needed\n","        self.fc = nn.Linear(self.bert.config.hidden_size, num_classes)\n","\n","    def forward(self, input_ids, attention_mask):\n","        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n","        pooled_output = outputs.pooler_output\n","        pooled_output = self.dropout(pooled_output)\n","        logits = self.fc(pooled_output)\n","        return logits\n"]},{"cell_type":"code","execution_count":15,"id":"0ab666c9","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0ab666c9","executionInfo":{"status":"ok","timestamp":1713072279759,"user_tz":-330,"elapsed":5,"user":{"displayName":"Lightning Thunder","userId":"16749741163451614519"}},"outputId":"bbbe679e-f156-4866-d7aa-ab4e5325b77e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Input IDs Shape: torch.Size([15988, 26])\n","Attention Mask Shape: torch.Size([15988, 26])\n","Labels Shape: torch.Size([15998])\n"]}],"source":["print(\"Input IDs Shape:\", train_tokenized['input_ids'].shape)\n","print(\"Attention Mask Shape:\", train_tokenized['attention_mask'].shape)\n","print(\"Labels Shape:\", torch.tensor(train_df['label'].tolist()).shape)"]},{"cell_type":"code","execution_count":16,"id":"2f882505","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2f882505","executionInfo":{"status":"ok","timestamp":1713072288308,"user_tz":-330,"elapsed":6046,"user":{"displayName":"Lightning Thunder","userId":"16749741163451614519"}},"outputId":"73d1a8e7-6045-477b-a2b8-90332da524b4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Sample of train_df:\n","                                                text  label  \\\n","0  My friends and I will have a beer party to che...      1   \n","1  Sometimes I woke up in the middle of the night...      1   \n","2  My friend introduce the wab lang-8 which can i...      0   \n","3  We talked many things through the night yester...      0   \n","4  Especially European must mind why I speak the ...      0   \n","\n","                                      processed_text  \n","0        friend beer party cheer korea football team  \n","1                sometimes woke middle night itching  \n","2         friend introduce wab lang8 improve english  \n","3  talked many thing night yesterday head hurt wa...  \n","4  especially european must mind speak letter r e...  \n","\n","Sample of val_df:\n","                                                text  label  \\\n","0        He said that he went for a swim in the sea.      1   \n","1           I would like to listen to operas loudly.      1   \n","2  Today, a Korean scientist has successfully mad...      1   \n","3  Because it continued the thought which I would...      1   \n","4  If you have been said to be\" powerful\" since y...      1   \n","\n","                                      processed_text  \n","0                                 said went swim sea  \n","1                     would like listen opera loudly  \n","2  today korean scientist successfully made soft ...  \n","3          continued thought would write diary later  \n","4                      said powerful since childhood  \n","\n","Sample of test_df:\n","                                                text  label  \\\n","0                And It is a good experience for me.      0   \n","1  After the vacation, I was very busy because I ...      1   \n","2                   I'm back from swimming pool now.      0   \n","3    I am a big fan of the Toronto Blue Jays of MLB.      1   \n","4  It’s a finish after sprinkling grilled meat sa...      0   \n","\n","                           processed_text  \n","0                         good experience  \n","1               vacation busy report work  \n","2                   im back swimming pool  \n","3            big fan toronto blue jay mlb  \n","4  ’ finish sprinkling grilled meat sauce  \n"]}],"source":["import pandas as pd\n","import torch\n","from torch.utils.data import DataLoader, TensorDataset\n","from transformers import BertTokenizer\n","\n","# Assuming train_df, val_df, and test_df are your DataFrames containing the data\n","# Initialize BERT tokenizer\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","\n","# Function to tokenize text data\n","def tokenize_text(df, tokenizer):\n","    tokenized_data = tokenizer(df['text'].tolist(), padding=True, truncation=True, return_tensors='pt', max_length=128, return_attention_mask=True)\n","    return tokenized_data\n","\n","# Load the data into DataFrames using the correct file paths\n","train_df = pd.read_csv('train_dataset.csv')\n","val_df = pd.read_csv('val_dataset.csv')\n","test_df = pd.read_csv('test_dataset.csv')\n","\n","\n","# Check the first few rows of each DataFrame\n","print(\"Sample of train_df:\")\n","print(train_df.head())\n","\n","print(\"\\nSample of val_df:\")\n","print(val_df.head())\n","\n","print(\"\\nSample of test_df:\")\n","print(test_df.head())\n","# Tokenize text data for train, validation, and test sets\n","train_tokenized = tokenize_text(train_df, tokenizer)\n","val_tokenized = tokenize_text(val_df, tokenizer)\n","test_tokenized = tokenize_text(test_df, tokenizer)\n","\n","# Filter the labels to match the number of input samples\n","filtered_labels_train = train_df['label'][:len(train_tokenized['input_ids'])]\n","filtered_labels_val = val_df['label'][:len(val_tokenized['input_ids'])]\n","filtered_labels_test = test_df['label'][:len(test_tokenized['input_ids'])]\n","\n","# Create TensorDataset for train, validation, and test sets\n","train_dataset = TensorDataset(train_tokenized['input_ids'], train_tokenized['attention_mask'], torch.tensor(filtered_labels_train.tolist()))\n","val_dataset = TensorDataset(val_tokenized['input_ids'], val_tokenized['attention_mask'], torch.tensor(filtered_labels_val.tolist()))\n","test_dataset = TensorDataset(test_tokenized['input_ids'], test_tokenized['attention_mask'], torch.tensor(filtered_labels_test.tolist()))\n","\n","# Create DataLoader for train, validation, and test sets\n","batch_size = 16\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size)\n"]},{"cell_type":"code","execution_count":17,"id":"1d47de7d","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1d47de7d","executionInfo":{"status":"ok","timestamp":1713072295473,"user_tz":-330,"elapsed":5436,"user":{"displayName":"Lightning Thunder","userId":"16749741163451614519"}},"outputId":"5b122fb3-3807-4a8c-be89-486f5ba21b99"},"outputs":[{"output_type":"stream","name":"stdout","text":["Length of Train Dataset: 15998\n","Length of Validation Dataset: 2000\n"]}],"source":["import pandas as pd\n","import torch\n","from torch.utils.data import DataLoader, TensorDataset\n","from transformers import BertTokenizer\n","\n","# Initialize BERT tokenizer\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","\n","# Function to tokenize text data\n","def tokenize_text(df, tokenizer):\n","    tokenized_data = tokenizer(df['text'].tolist(), padding=True, truncation=True, return_tensors='pt', max_length=128, return_attention_mask=True)\n","    return tokenized_data\n","\n","# Tokenize text data for train and validation sets\n","train_tokenized = tokenize_text(train_df, tokenizer)\n","val_tokenized = tokenize_text(val_df, tokenizer)\n","\n","# Filter the labels to match the number of input samples\n","filtered_labels_train = train_df['label'][:len(train_tokenized['input_ids'])]\n","filtered_labels_val = val_df['label'][:len(val_tokenized['input_ids'])]\n","\n","# Create TensorDataset for train and validation sets\n","train_dataset = TensorDataset(train_tokenized['input_ids'], train_tokenized['attention_mask'], torch.tensor(filtered_labels_train.tolist()))\n","val_dataset = TensorDataset(val_tokenized['input_ids'], val_tokenized['attention_mask'], torch.tensor(filtered_labels_val.tolist()))\n","\n","# Create DataLoader for train and validation sets\n","batch_size = 16\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size)\n","\n","# Check the lengths of the datasets\n","print(\"Length of Train Dataset:\", len(train_dataset))\n","print(\"Length of Validation Dataset:\", len(val_dataset))\n"]},{"cell_type":"code","execution_count":42,"id":"802d2a6b","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"802d2a6b","executionInfo":{"status":"ok","timestamp":1713074841792,"user_tz":-330,"elapsed":370107,"user":{"displayName":"Lightning Thunder","userId":"16749741163451614519"}},"outputId":"33ba3fbd-d315-4649-a75e-c25ab80bc8fe"},"outputs":[{"output_type":"stream","name":"stdout","text":["GPU is available\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/3, Training Loss: 0.4557011606395245,  Validation Accuracy: 83.6%\n","Epoch 2/3, Training Loss: 0.2530675543136895,  Validation Accuracy: 84.25%\n","Epoch 3/3, Training Loss: 0.12160702615557238,  Validation Accuracy: 83.15%\n"]}],"source":["import pandas as pd\n","import torch\n","from torch.utils.data import DataLoader, TensorDataset\n","from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n","\n","# Check for GPU availability\n","if torch.cuda.is_available():\n","    device = torch.device(\"cuda\")\n","    print(\"GPU is available\")\n","else:\n","    device = torch.device(\"cpu\")\n","    print(\"GPU is not available, using CPU instead\")\n","\n","# Initialize BERT tokenizer\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","\n","# Function to tokenize text data\n","def tokenize_text(df, tokenizer):\n","    tokenized_data = tokenizer(df['text'].tolist(), padding=True, truncation=True, return_tensors='pt', max_length=128, return_attention_mask=True)\n","    return tokenized_data\n","\n","# Load the data into DataFrames using the correct file paths\n","train_df = pd.read_csv('train_dataset.csv')\n","val_df = pd.read_csv('val_dataset.csv')\n","test_df = pd.read_csv('test_dataset.csv')\n","\n","# Tokenize text data for train, validation, and test sets\n","train_tokenized = tokenize_text(train_df, tokenizer)\n","val_tokenized = tokenize_text(val_df, tokenizer)\n","test_tokenized = tokenize_text(test_df, tokenizer)\n","\n","# Filter the labels to match the number of input samples\n","filtered_labels_train = train_df['label'][:len(train_tokenized['input_ids'])]\n","filtered_labels_val = val_df['label'][:len(val_tokenized['input_ids'])]\n","filtered_labels_test = test_df['label'][:len(test_tokenized['input_ids'])]\n","\n","# Create TensorDataset for train, validation, and test sets\n","train_dataset = TensorDataset(train_tokenized['input_ids'], train_tokenized['attention_mask'], torch.tensor(filtered_labels_train.tolist()))\n","val_dataset = TensorDataset(val_tokenized['input_ids'], val_tokenized['attention_mask'], torch.tensor(filtered_labels_val.tolist()))\n","test_dataset = TensorDataset(test_tokenized['input_ids'], test_tokenized['attention_mask'], torch.tensor(filtered_labels_test.tolist()))\n","\n","# Create DataLoader for train, validation, and test sets\n","batch_size = 16\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size)\n","\n","# Initialize BERT model for sequence classification\n","model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2).to(device)\n","\n","# Define the optimizer and loss function\n","optimizer = AdamW(model.parameters(), lr=2e-5)\n","\n","# Training loop\n","num_epochs = 3\n","for epoch in range(num_epochs):\n","    model.train()\n","    running_loss = 0.0\n","    for batch in train_loader:\n","        input_ids, attention_mask, labels = batch\n","        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()\n","\n","        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n","        loss = outputs.loss\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","\n","    # Evaluate the model on the validation set\n","    model.eval()\n","    val_loss = 0.0\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for batch in val_loader:\n","            input_ids, attention_mask, labels = batch\n","            input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n","\n","            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n","            loss = outputs.loss\n","            val_loss += loss.item()\n","\n","            _, predicted = torch.max(outputs.logits, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {running_loss/len(train_loader)},  Validation Accuracy: {(correct/total)*100}%\")\n","\n","\n","# Save the trained model\n","torch.save(model.state_dict(), 'bert_model.pth')"]},{"cell_type":"code","source":["import torch\n","from sklearn.metrics import classification_report, accuracy_score\n","\n","# Function to evaluate the model\n","def evaluate_model(model, dataloader):\n","\n","    model.eval()  # Set the model to evaluation mode\n","    all_predictions = []\n","    all_labels = []\n","\n","    with torch.no_grad():\n","        for batch in dataloader:\n","            input_ids, attention_mask, labels = batch\n","            input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n","\n","            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n","            _, predicted = torch.max(outputs.logits, 1)\n","\n","            # Convert tensors to numpy arrays and extend lists\n","            all_predictions.extend(predicted.cpu().numpy())\n","            all_labels.extend(labels.cpu().numpy())\n","\n","    return all_predictions, all_labels\n","\n","# Evaluate the model on the validation set\n","val_predictions, val_labels = evaluate_model(model, val_loader)\n","\n","# Calculate classification report\n","classification_rep = classification_report(val_labels, val_predictions)\n","print(\"Classification Report for Validation Set:\")\n","print(classification_rep)\n","\n","# Calculate accuracy\n","accuracy = accuracy_score(val_labels, val_predictions)\n","print(\"Accuracy on Validation Set:\", accuracy)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qGB-XpL221jQ","executionInfo":{"status":"ok","timestamp":1713074855796,"user_tz":-330,"elapsed":3899,"user":{"displayName":"Lightning Thunder","userId":"16749741163451614519"}},"outputId":"1dddf324-ddf6-47ca-d719-e92c5658846e"},"id":"qGB-XpL221jQ","execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["Classification Report for Validation Set:\n","              precision    recall  f1-score   support\n","\n","           0       0.88      0.76      0.81       969\n","           1       0.80      0.90      0.85      1031\n","\n","    accuracy                           0.83      2000\n","   macro avg       0.84      0.83      0.83      2000\n","weighted avg       0.84      0.83      0.83      2000\n","\n","Accuracy on Validation Set: 0.8315\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import torch\n","from transformers import DistilBertForSequenceClassification, DistilBertTokenizer\n","from torch.utils.data import DataLoader\n","\n","def classify_text_from_excel(input_file, output_file, model, tokenizer, device):\n","    # Read input data from Excel file\n","    df = pd.read_excel(input_file)\n","\n","    # Select only the first 1000 rows\n","    df = df.head(1000)\n","\n","    # Convert text column to a list of strings\n","    text_list = df['text'].astype(str).tolist()\n","\n","    # Process text inputs\n","    tokenized_data = tokenizer(text_list, padding=True, truncation=True, return_tensors='pt', max_length=128, return_attention_mask=True)\n","    input_ids = tokenized_data['input_ids'].to(device)\n","    attention_mask = tokenized_data['attention_mask'].to(device)\n","\n","    # Move model to device\n","    model.to(device)\n","\n","    # Predict labels using the model\n","    with torch.no_grad():\n","        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n","    predictions = torch.argmax(outputs.logits, axis=1).cpu().numpy()\n","\n","    # Add predictions to DataFrame\n","    df['predicted_label'] = predictions\n","\n","    # Save DataFrame with predictions back to Excel file\n","    df.to_excel(output_file, index=False)\n","\n","# Initialize tokenizer and model\n","tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n","model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')\n","\n","# Set device\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Input and output filenames\n","input_filename = '/content/sample_data/test_data.xlsx'\n","output_filename = 'output_file_only_labeled.xlsx'\n","\n","# Call the function to classify text from Excel\n","classify_text_from_excel(input_filename, output_filename, model, tokenizer, device)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LJHXKvhuXuDP","executionInfo":{"status":"ok","timestamp":1713074921855,"user_tz":-330,"elapsed":4016,"user":{"displayName":"Lightning Thunder","userId":"16749741163451614519"}},"outputId":"12d5c6fa-dc7c-4180-ca83-26a4d7ec5045"},"id":"LJHXKvhuXuDP","execution_count":46,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","execution_count":47,"id":"76d8a769","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"76d8a769","executionInfo":{"status":"ok","timestamp":1713074979490,"user_tz":-330,"elapsed":33021,"user":{"displayName":"Lightning Thunder","userId":"16749741163451614519"}},"outputId":"b0bd3231-9e11-4cc7-c3c9-a4e4df31b625"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Enter your sentence: Jeff ran a mile and drops his keys.\n","The sentence contains grammar errors.\n"]}],"source":["import torch\n","from transformers import BertTokenizer, BertForSequenceClassification\n","\n","# Initialize BERT tokenizer and load pretrained model\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n","model.load_state_dict(torch.load('bert_model.pth'))\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","model.eval()\n","\n","# Function to validate user sentence\n","def validate_sentence(sentence):\n","    # Tokenize the input sentence\n","    inputs = tokenizer(sentence, padding=True, truncation=True, return_tensors='pt').to(device)\n","\n","    # Pass input through the model\n","    with torch.no_grad():\n","        outputs = model(**inputs)\n","\n","    # Interpret predictions\n","    prediction = torch.argmax(outputs.logits).item()\n","    if prediction == 1:\n","        print(\"The sentence is grammatically correct.\")\n","    else:\n","        print(\"The sentence contains grammar errors.\")\n","\n","# Get user input\n","user_sentence = input(\"Enter your sentence: \")\n","\n","# Validate the user sentence\n","validate_sentence(user_sentence)\n"]},{"cell_type":"code","source":["import pandas as pd\n","import torch\n","from transformers import DistilBertForSequenceClassification, DistilBertTokenizer\n","from torch.utils.data import DataLoader\n","from nltk import pos_tag, word_tokenize\n","\n","\n","nltk.download('averaged_perceptron_tagger')\n","\n","# Function to validate sentence for grammatical errors\n","def validate_sentence(sentence):\n","    # Ensure that the input is a string\n","    if not isinstance(sentence, str):\n","        return 1, \"None\"  # No error\n","\n","    # Tokenize the input sentence\n","    tokens = word_tokenize(sentence)\n","\n","    # Get Part-of-Speech tags for the tokens\n","    pos_tags = pos_tag(tokens)\n","\n","    # Check for grammatical errors\n","    error_type = None\n","    for i in range(len(pos_tags)-1):\n","        # Rule 1: Subject-Verb Agreement\n","        if pos_tags[i][1].startswith('N') and pos_tags[i+1][1].startswith('VB'):\n","            error_type = \"Subject-Verb Agreement\"\n","            return 0, error_type  # Error found\n","\n","        # Rule 2: Present Simple Tense\n","        if pos_tags[i][1] == 'VBP' and pos_tags[i][0].endswith('s'):\n","            error_type = \"Present Simple Tense\"\n","            return 0, error_type  # Error found\n","\n","        # Rule 3: Present Continuous Tense\n","        if pos_tags[i][1] == 'VBG' and pos_tags[i][0] != 'am':\n","            error_type = \"Present Continuous Tense\"\n","            return 0, error_type  # Error found\n","\n","        # Rule 4: Present Perfect Tense\n","        if pos_tags[i][1] == 'VBN' and pos_tags[i][0] != 'been':\n","            error_type = \"Present Perfect Tense\"\n","            return 0, error_type  # Error found\n","\n","        # Rule 5: Present Perfect Continuous Tense\n","        if pos_tags[i][1] == 'VBG' and pos_tags[i][0] == 'been':\n","            error_type = \"Present Perfect Continuous Tense\"\n","            return 0, error_type  # Error found\n","\n","        # Rule 6: Past Simple Tense\n","        if pos_tags[i][1] == 'VBD' and not pos_tags[i][0].endswith('ed'):\n","            error_type = \"Past Simple Tense\"\n","            return 0, error_type  # Error found\n","\n","        # Rule 7: Past Continuous Tense\n","        if pos_tags[i][1] == 'VBD' and pos_tags[i][0] == 'were':\n","            error_type = \"Past Continuous Tense\"\n","            return 0, error_type  # Error found\n","\n","        # Rule 8: Past Perfect Tense\n","        if pos_tags[i][1] == 'VBN' and pos_tags[i][0] != 'had':\n","            error_type = \"Past Perfect Tense\"\n","            return 0, error_type  # Error found\n","\n","        # Rule 9: Past Perfect Continuous Tense\n","        if pos_tags[i][1] == 'VBN' and pos_tags[i][0] == 'had':\n","            error_type = \"Past Perfect Continuous Tense\"\n","            return 0, error_type  # Error found\n","\n","        # Rule 10: Future Simple Tense\n","        if pos_tags[i][1] == 'MD' and pos_tags[i][0] not in ['will', 'shall']:\n","            error_type = \"Future Simple Tense\"\n","            return 0, error_type  # Error found\n","\n","        # Rule 11: Future Continuous Tense\n","        if pos_tags[i][1] == 'MD' and pos_tags[i][0] in ['will', 'shall']:\n","            error_type = \"Future Continuous Tense\"\n","            return 0, error_type  # Error found\n","\n","        # Rule 12: Future Perfect Tense\n","        if pos_tags[i][1] == 'MD' and pos_tags[i][0] in ['will', 'shall']:\n","            error_type = \"Future Perfect Tense\"\n","            return 0, error_type  # Error found\n","\n","        # Rule 13: Future Perfect Continuous Tense\n","        if pos_tags[i][1] == 'MD' and pos_tags[i][0] in ['will', 'shall']:\n","            error_type = \"Future Perfect Continuous Tense\"\n","            return 0, error_type  # Error found\n","\n","    return 1, \"None\"  # No error\n","\n","# Function to classify text from Excel file\n","def classify_text_from_excel(input_file, output_file, model, tokenizer, device):\n","    # Read input data from Excel file\n","    df = pd.read_excel(input_file)\n","\n","    # Select only the first 1000 rows\n","    df = df.head(1000)\n","\n","    # Convert text column to a list of strings\n","    text_list = df['text'].astype(str).tolist()\n","\n","    # Process text inputs\n","    tokenized_data = tokenizer(text_list, padding=True, truncation=True, return_tensors='pt', max_length=128, return_attention_mask=True)\n","    input_ids = tokenized_data['input_ids'].to(device)\n","    attention_mask = tokenized_data['attention_mask'].to(device)\n","\n","    # Move model to device\n","    model.to(device)\n","\n","    # Predict labels using the model\n","    with torch.no_grad():\n","        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n","    predictions = torch.argmax(outputs.logits, axis=1).cpu().numpy()\n","\n","\n","    # Add columns for grammatical error detection and error type\n","    df['label'], df['error_type'] = zip(*df['text'].apply(validate_sentence))\n","\n","    # Save DataFrame with predictions, error detection, and error type back to Excel file\n","    df.to_excel(output_file, index=False)\n","\n","# Initialize tokenizer and model\n","tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n","model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')\n","\n","# Set device\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Input and output filenames\n","input_filename = '/content/sample_data/test_data.xlsx'\n","output_filename = 'output_file.xlsx'\n","\n","# Call the function to classify text from Excel\n","classify_text_from_excel(input_filename, output_filename, model, tokenizer, device)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8ZBx8poYfpQe","executionInfo":{"status":"ok","timestamp":1713074991273,"user_tz":-330,"elapsed":4930,"user":{"displayName":"Lightning Thunder","userId":"16749741163451614519"}},"outputId":"7404a785-60d4-4028-decf-b2b311faf3cd"},"id":"8ZBx8poYfpQe","execution_count":48,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"},"colab":{"provenance":[{"file_id":"1Ri3tIdvrehY7MpusZ35zkiNzqlpPzV6-","timestamp":1712904347206}],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}